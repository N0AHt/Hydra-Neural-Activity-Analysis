{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single Cell Resolution Analysis of Ca Imaging Data for Hydra v4** \n",
    "=============================================================\n",
    "*(Use with data from tdTomato_GCamP Animals)*\n",
    "\n",
    "Requires:\n",
    "-------------------------\n",
    "- Green and Red Channel Videos From 2-Colour Confocal (GCaMP Channel and tdTomato)\n",
    "- Tracking Position Information From ICY Spot Tracking Protocol (Exported as CSV)\n",
    "- Conda Environment: Caiman_NOAH3\n",
    "- SCHyA .py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUT PATHS\n",
    "-----------------\n",
    "Enter paths to the appropriate files                    \n",
    "**Videos must be .avi (convert in imageJ if not)**     \n",
    "**Can also use a Tif sequence folder - change the read data function to Read_Data_TIFseq for this**    \n",
    "**If using windows**: Paths must start with an 'r' character: e.g. vid_path = **r**\"C:\\Users\\rylab\\ path to your file \\clip.avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input path to your .csv from ICY\n",
    "csv_path = '/Users/noah/Documents/Columbia_Project/thesis_dump/VID1_oct_4_3hz/AVIs_and_CSV/points.csv'\n",
    "\n",
    "#input path to .avi of GCaMP Video\n",
    "vid_path = '/Users/noah/Documents/Columbia_Project/thesis_dump/VID1_oct_4_3hz/AVIs_and_CSV/green(1-852).avi'\n",
    "\n",
    "#input path to .avi of tdTomato Video\n",
    "red_vid_path = '/Users/noah/Documents/Columbia_Project/thesis_dump/VID1_oct_4_3hz/AVIs_and_CSV/red(1-852).avi'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET UP DATA  \n",
    "-----------------------\n",
    "Run the following cells to set up the \n",
    "data to be analysed        \n",
    "**Set the FFmpeg path before running this cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noah/anaconda3/envs/syfi/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.decomposition.incremental_pca module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.decomposition. Anything that cannot be imported from sklearn.decomposition is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/noah/anaconda3/envs/syfi/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/noah/anaconda3/envs/syfi/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/noah/anaconda3/envs/syfi/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/noah/anaconda3/envs/syfi/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/noah/anaconda3/envs/syfi/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/noah/anaconda3/envs/syfi/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#importing packages\n",
    "\n",
    "import SCHyA as hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in data\n",
    "positions, vid, red_vid = hy.Read_Data(csv_path, vid_path, red_vid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the .csv into a more useable form\n",
    "posit = hy.reshaper(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of Frames in Green Video: 852\n",
      "Number of Frames in Red Video: 852\n",
      "Number of Points Tracked by ICY: 713\n"
     ]
    }
   ],
   "source": [
    "#Get Information About Raw Data\n",
    "num_frames = len(vid)\n",
    "num_red_frames = len(red_vid)\n",
    "num_tracks = int(positions[len(positions)-1,0])\n",
    "#Display Information\n",
    "print('Numer of Frames in Green Video:', num_frames)\n",
    "print('Number of Frames in Red Video:', num_red_frames)\n",
    "print('Number of Points Tracked by ICY:', num_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCIUM SIGNAL EXTRACTION\n",
    "------------------------\n",
    "These following cells will remove neurons that were not completely tracked throughout the video, extract a region of interest around each fully tracked neuron, and extract the intensity of each neuron throughout the video and plot the raw intensities. The signal can then be corrected for motion artefacts by finding the ratiometric signal between the green and red channels - dR/R; or through the use of Independant Component Analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discard Neurons which were incompletely tracked\n",
    "posit_corrected = hy.remove_incomplete_tracks(posit, num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Following 2 Cells may Give a Runtime Warning - This is Fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Must Run the Extract_Fluorescence function before the SingleCellIntensities function as you need to use the updated 'posit_corrected' output from Extract_Fluorescence as SingleCellIntensities as no feature to correct this itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noah/anaconda3/envs/syfi/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/noah/anaconda3/envs/syfi/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'posit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-216fea3a6cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mintensities1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposit_corrected1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtract_Fluorescence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposit_corrected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mintensities1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposit_corrected1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneuron_pts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSingleCellIntensities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposit_corrected1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubROI_Circle_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLookBack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/github/Hydra-Neural-Activity-Analysis/Neural Activity Analysis/SCHyA.py\u001b[0m in \u001b[0;36mSingleCellIntensities\u001b[0;34m(video, positions, dimentionROI, Circle_radius, distance_threshold)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0mall_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrack\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0mintensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposits_corr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleCellIntensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimentionROI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCircle_radius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0mintensities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintensity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mposition_updated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/Hydra-Neural-Activity-Analysis/Neural Activity Analysis/SCHyA.py\u001b[0m in \u001b[0;36mSingleCellIntensity\u001b[0;34m(neuron, video, positions, dimentionROI, Circle_radius, distance_threshold, display_on)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;31m#         print('max: ', np.max(image_out))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mintensities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mpositions_corrected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdisplay_on\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mintensities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions_corrected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneuron_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'posit' is not defined"
     ]
    }
   ],
   "source": [
    "#Extract the fluorescence intensity in the GCaMP channel throughout the video for each neuron\n",
    "\n",
    "#size of ROI\n",
    "dim = 9\n",
    "subROI_Circle_size = 4\n",
    "LookBack = 4 #resistance of tracking to movement i.e. how quickly a tracked neuron can move before position resets\n",
    "\n",
    "intensities1, posit_corrected1 = hy.Extract_Fluorescence(posit_corrected, vid, dimention = dim)\n",
    "\n",
    "intensities1, posit_corrected1, neuron_pts = hy.SingleCellIntensities(vid, posit_corrected1, dim, subROI_Circle_size, LookBack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the fluorescence intensity in the Red channel throughout the video for each neuron\n",
    "\n",
    "intensities_red, posit_corrected = Extract_Fluorescence(posit_corrected1, red_vid, dim)\n",
    "\n",
    "# intensities_red = SingleCellIntensities_Red(red_vid, neuron_pts, posit_corrected, dim, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot raw neuronal intensities & display number of fully tracked neurons\n",
    "number_of_neurons = len(intensities1)\n",
    "print('number of neurons = ', number_of_neurons)\n",
    "\n",
    "for track in range(len(intensities1)):\n",
    "    plt.plot(intensities1[track])\n",
    "    plt.title('Raw GCaMP Intensity plots of all sufficiently recorded neurons')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Intenstiy')\n",
    "plt.show()\n",
    "\n",
    "#Plot intensities of red channels - used to identify motion artefacts and leaking between channels\n",
    "for track in range(len(intensities1)):\n",
    "    plt.plot(intensities_red[track])\n",
    "    plt.title('Intensity Plot of Red Channel')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Neuron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DeltaR/R or ICA used to correct for motion artefacts and cross channel leaking\n",
    "#Obtain Artefact Free Ca Signal\n",
    "CaSignal = ICAdecorr(intensities1, intensities_red, 0.5, 10)\n",
    "\n",
    "#Plot Signal\n",
    "for i in range(len(CaSignal)):\n",
    "    plt.plot(CaSignal[i])\n",
    "plt.title('Extracted Calcium Signal Plot')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Ca Intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Heatmap of Calcium Signal\n",
    "#can normalise here for better signal...\n",
    "plot_heatmap(CaSignal, 'Heatmap of Extracted Calcium Signal', 'Ca Signal Intensity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcium Signal Extraction - Optional Cells\n",
    "--------------------------\n",
    "**These Cells Dont Need to be Run**          \n",
    "Cells for evaluating performance or saving preliminary results        \n",
    "Only Run the Cells you want to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Cells to Evaluate ROI Tracking**      \n",
    "Input frame number to view all of the ROIs tracked in that frame      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#superimpose ROIs on video frame in both channels\n",
    "\n",
    "#select frame to view\n",
    "frame_to_view = 510\n",
    "\n",
    "Super_impose(vid, frame_to_view, 'Neuron Tracking in Green Channel')\n",
    "Super_impose(red_vid, frame_to_view, 'Neuron Tracking in Red Channel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Cells to Evaluate Effect and Correction of Motion Artifacts and Red Leakage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Raw Transients in Green\n",
    "plot_all(intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Red Transient to check for motion artefacts and leaking\n",
    "Neuron_with_possible_artefact = 52\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Raw Red Channel Plot')\n",
    "plt.plot(intensities_red[Neuron_with_possible_artefact])\n",
    "plt.show()\n",
    "\n",
    "#After Correction:\n",
    "plt.figure(2)\n",
    "plt.plot(CaSignal[Neuron_with_possible_artefact])\n",
    "plt.title('Calcium Signal Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Cell to Evaluate Activity and Tracking of Individual Neurons**     \n",
    "Allows comparison between intensity trace of a neuron and that neuron's ROI at a particular frame    \n",
    "Input Neuron Number and Frame Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input neuron to check\n",
    "neuron = 42\n",
    "\n",
    "#input frame form video to view the ROI\n",
    "eval_frame = 509\n",
    "\n",
    "full_eval(neuron, CaSignal, eval_frame, dim, posit_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILTERING & SMOOTHING\n",
    "-----------------------\n",
    "\n",
    "The following cells will filter the intensity traces of the neurons to remove signal that are likely from nematocytes, smooth the results to reduce the appearance of noise, and detrend the resulting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detrending data - use on filtered or smoothed data\n",
    "\n",
    "#Set Polynomial Degree\n",
    "poly_deg = 17\n",
    "\n",
    "detrended = detrend_all(CaSignal, poly_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Nematocytes\n",
    "\n",
    "#set the threshold to remove below\n",
    "#standard option is to set to 20 (i.e. filter will remove signals with below the 20th percentile of standard deviations)\n",
    "\n",
    "# percentile_threshold = 0 #zero = no filtering\n",
    "# filt, posit_corrected = filt_nematocytes(CaSignal,percentile_threshold,posit_corrected)\n",
    "\n",
    "alpha = 1e-6 #Tune threshold for coherence to gaussian distribution - need to use detrended data with this function\n",
    "detrended, posit_corrected, removed = Gaussian_noise_filter(detrended, alpha, posit_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate filtering of neurons\n",
    "\n",
    "plot_all(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smooth Signals\n",
    "\n",
    "# #Set Smoothing window Size\n",
    "# window = 2\n",
    "\n",
    "# smooth_intensities = smoother(filt, window)\n",
    "# detrended = smooth_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Filtering and Smoothing Results\n",
    "\n",
    "#Display Total Number of Neurons After Filtering\n",
    "print('no of neurons: ', len(detrended))\n",
    "\n",
    "# plt.figure(1)\n",
    "# for i in range(len(filt)):\n",
    "#     plt.plot(filt[i])\n",
    "# plt.title('Calcium Signal with Nematocytes Filtered')\n",
    "# plt.xlabel('Frame')\n",
    "# plt.ylabel('Calcium Signal')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(2)\n",
    "# for i in range(len(smooth_intensities)):\n",
    "#     plt.plot(smooth_intensities[i])\n",
    "# plt.title('Smoothed Filtered Fluorescence with Single Neuron Resolution')\n",
    "# plt.xlabel('Frame')\n",
    "# plt.ylabel('Calcium Signal')\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "for i in range(len(detrended)):\n",
    "    plt.plot(detrended[i])\n",
    "plt.title('Detrended Calcium Signal Data')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Calcium Signal Detrended')\n",
    "plt.show()\n",
    "\n",
    "plot_heatmap(norm_all_data(detrended), 'Heatmap of Filtered Detrended Data', 'Calcium Signal Intensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all remaining neurons after filtering and processing\n",
    "plot_all(detrended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCIUM SIGNAL ANALYSIS\n",
    "-------------------------------------\n",
    "\n",
    "The following cells analyse the results to show extract spikes from the Calcium intensity data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tune Threshold used to Indentify Spikes to Fit Data Using Evaluation Cell for FOOPSI at End of Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Raster Plot using CAIMAN's FOOPSI function - Denoising and Deconvolution\n",
    "\n",
    "#foopsi\n",
    "Foopsi_ca, spikes_signal_dR = FOOPSI_all(detrended)\n",
    "\n",
    "#Extract Raster Plot Data\n",
    "\n",
    "#Threshold (could use a theoretical value for threshold! - See CAIMAN Docs - but trial & error is also fine)\n",
    "#USE FOOPSI EVALUATION CELL TO TUNE THIS PARAMETER (0.04 works well)\n",
    "spike_thresh_dR = 0.2\n",
    "\n",
    "raster_array_dR = Find_Raster_adaptive(spikes_signal_dR, spike_thresh_dR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all denoised calcium traces\n",
    "plot_all(Foopsi_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(norm_all_data(Foopsi_ca), 'Denoised heatmap', 'Intensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Results\n",
    "\n",
    "#plot raster\n",
    "#zero values from way array was made array give large syncronous train at start of the signal - should fix (.append method?)\n",
    "plt.figure(2)\n",
    "plt.eventplot(raster_array_dR,linelengths = 0.6)\n",
    "plt.ylabel('Neuron')\n",
    "plt.xlabel('Frame')\n",
    "plt.title('Raster Plot of Neural Activity of Hydra')\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot rasterplot for all neurons\n",
    "for i in range(len(raster_array_dR)):\n",
    "    plt.eventplot(raster_array_dR[i],linelengths = 0.6)\n",
    "    plt.xlim((1,len(raster_array_dR[0])))\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEHAVIOUR ANALYSIS WITH NEURAL ACTIVITY\n",
    "---------------------------------------------\n",
    "These cells plot neural activity and behaviour together to allow comparision between neural activity and behaviour     \n",
    "Most of this step still needs to be done by hand unfortunately..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Behaviour Arrays\n",
    "\n",
    "#behaviour array: [frame behaviour turns on,frame off,on,off,on,... etc]\n",
    "behaviour_frames = [0,212,605,len(detrended[0])]\n",
    "\n",
    "#fill with numbered behaviourws in order they occur\n",
    "behaviours = [1,0,1]\n",
    "\n",
    "#fill with colours corresponding to numbered behaviours\n",
    "colours=['blue','green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Neural Activity with Behaviour\n",
    "\n",
    "plt.figure(1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.02)\n",
    "for behav in range(len(behaviour_frames)-1):\n",
    "    colour_face = colours[behaviours[behav]]\n",
    "    ax.axvspan(behaviour_frames[behav],behaviour_frames[behav+1], facecolor = colour_face, alpha = 0.2)\n",
    "for i in range(len(intensities)):\n",
    "    plt.plot(intensities[i])\n",
    "plt.title('Raw Intensities plotted with CB and RP behaviour (CB=green)')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Intensity')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.02)\n",
    "for behav in range(len(behaviour_frames)-1):\n",
    "    colour_face = colours[behaviours[behav]]\n",
    "    ax.axvspan(behaviour_frames[behav],behaviour_frames[behav+1], facecolor = colour_face, alpha = 0.2)\n",
    "for i in range(len(detrended)):\n",
    "    plt.plot(detrended[i])\n",
    "plt.title('Processed Intensities plotted with CB and RP behaviour (CB=green)')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Calcium Signal Intensities Detrended')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.02)\n",
    "for behav in range(len(behaviour_frames)-1):\n",
    "    colour_face = colours[behaviours[behav]]\n",
    "    ax.axvspan(behaviour_frames[behav],behaviour_frames[behav+1], facecolor = colour_face,alpha = 0.2)\n",
    "plt.eventplot(raster_array_dR,linelengths = 0.6)\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.ylabel('Neuron')\n",
    "plt.xlabel('Frame')\n",
    "plt.title('Raster Plot of Neural Activity of Hydra Plotted with Behaviour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION AND INTERPRETATION OF DATA\n",
    "-----------------------------------\n",
    "The following cells work to group neurons together into ensembles, display various froms of correlation data presentation, and correlate each neuron to different types of behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Correlation Threshold to be Used to Group Neurons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dendogram (can change method between ward, average, etc)\n",
    "CaSignal_norm = spikes_signal_dR\n",
    "plt.figure(figsize=(10, 7))  \n",
    "plt.title(\"Dendrograms\")  \n",
    "dend = shc.dendrogram(shc.linkage(CaSignal_norm, method='ward'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Number of Clusters Based on Results from Dendogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract and view neurons from each cluster \n",
    "\n",
    "#number of clusters chosen from examination of dendogram\n",
    "number_of_clusters = 5\n",
    "\n",
    "clusters = give_cluster_assigns(pd.DataFrame(CaSignal_norm), number_of_clusters, transpose=False)\n",
    "clusters = clusters.values\n",
    "\n",
    "#plot specific cluster's neurons traces\n",
    "\n",
    "cluster_to_view = 2\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    if clusters[i] == cluster_to_view:\n",
    "        plt.figure(i-1)\n",
    "        plt.title(i)\n",
    "        plt.plot(Foopsi_ca[i])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Super impose locations of neurons in specified Cluster onto video frame\n",
    "\n",
    "cluster_to_view = 1\n",
    "frame_for_cluster = 30\n",
    "video_for_cluster = vid\n",
    "title_for_cluster = 'Cluster Positions'\n",
    "\n",
    "Super_impose_cluster(video = video_for_cluster, frame_to_view = frame_for_cluster, posit_corrected = posit_corrected, clusters = clusters, cluster_to_view = cluster_to_view, Title = title_for_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ClusterMap\n",
    "#change figure size to see all labels if necessary\n",
    "\n",
    "df = pd.DataFrame(np.transpose(CaSignal_norm))\n",
    "\n",
    "# Draw the full plot\n",
    "sns.clustermap(df.corr(), center=0, cmap=\"coolwarm\",linewidths=.75, figsize=(19, 19), method = 'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investigate Correlations from ClusterMap\n",
    "\n",
    "#input neurons to view\n",
    "neuron_1 = 7\n",
    "neuron_2 = 14\n",
    "\n",
    "plt.figure(1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.02)\n",
    "for behav in range(len(behaviour_frames)-1):\n",
    "    colour_face = colours[behaviours[behav]]\n",
    "    ax.axvspan(behaviour_frames[behav],behaviour_frames[behav+1], facecolor = colour_face,alpha = 0.2)\n",
    "plt.plot(detrended[neuron_1])\n",
    "plt.plot(detrended[neuron_2])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title(neuron_1)\n",
    "plt.eventplot(raster_array_dR[neuron_1],linelengths = 0.6)\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.title(neuron_2)\n",
    "plt.eventplot(raster_array_dR[neuron_2],linelengths = 0.6)\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single neuron investigation\n",
    "\n",
    "neuron_to_investigate = 33\n",
    "frame_to_investigate = 200\n",
    "\n",
    "single_neuron_investigation(neuron_to_investigate, CaSignal, vid, frame_to_investigate, dim, posit_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Data**\n",
    "===============\n",
    "**Optional Cells to Save Results**        \n",
    "Run these cells to save the data as a .csv         \n",
    "Input file name and path where file should be saved           \n",
    "**On Windows: Paths still need to start with 'r'**              \n",
    "e.g. r'C:\\Users\\rylab\\Documents\\path to your folder\\title.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Raw GCamp Intensity Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Raw GCamp Intensity data as a .csv \n",
    "\n",
    "# Save_Path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\hydra_Vids\\2-colour\\single_cell_intensity_behaviour_longclip.csv'\n",
    "\n",
    "# intensity_dataframe = pd.DataFrame(intensities)\n",
    "# intensity_dataframe.to_csv(Save_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save CaSignal Intensity Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save CaSignal data to .csv\n",
    "\n",
    "# Ca_save_path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\hydra_Vids\\2-colour\\single_cell_CaSig.csv'\n",
    "\n",
    "# intensity_dataframe = pd.DataFrame(CaSignal)\n",
    "# intensity_dataframe.to_csv(Ca_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sava Detrended Intensity Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save detrended data to .csv\n",
    "\n",
    "# dR_detrend_save_path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\hydra_Vids\\2-colour\\single_cell_detrend.csv'\n",
    "\n",
    "# dfintensity_dataframe = pd.DataFrame(detrended)\n",
    "# dfintensity_dataframe.to_csv(dR_detrend_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Foopsi De-noised Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save Foopsi de-noised data to .csv\n",
    "\n",
    "# Ca_denoised_path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\Project_Behaviour_and_Neural_Activity\\Single_Cell_Analysis_Neural\\Single_Cell_Data\\VID1_oct_4_3hz\\Results\\denoised_neuraldata.csv'\n",
    "\n",
    "# ca_dataframe = pd.DataFrame(Foopsi_ca)\n",
    "# ca_dataframe.to_csv(Ca_denoised_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Raster Plot Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save raster data to .csv (needs to be reformatted from event plot form first)\n",
    "\n",
    "# raster_save_path = r'C:\\Users\\rylab\\Documents\\Noah2019_desktop\\Columbia_Project\\hydra_Vids\\2-colour\\single_cell_rasterb1.csv'\n",
    "\n",
    "# raster_array_pred = np.zeros((len(raster_array_dR),len(raster_array_dR[1])))\n",
    "# for i in range(len(spikes_signal_dR)):\n",
    "#     for j in range(len(spikes_signal_dR[i])):\n",
    "#         if max(spikes_signal_dR[i]) > 0:\n",
    "#             if spikes_signal_dR[i][j] >= spike_thresh_dR: #*np.mean(spikes_signal_dR[i]):\n",
    "#                 raster_array_pred[i][j] = 1\n",
    "\n",
    "# raster_dataframe = pd.DataFrame(raster_array_pred)\n",
    "# raster_dataframe.to_csv(raster_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Behaviour Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Behaviour Array tp .csv\n",
    "# behaviour_Save_Path = r\"C:\\Users\\rylab\\Downloads\\behav_array.csv\"\n",
    "\n",
    "# behav_array = np.zeros(len(vid))\n",
    "# for i in range(len(behaviours)):\n",
    "#     behav_array[behaviour_frames[i]:behaviour_frames[i+1]] = behaviours[i]\n",
    "    \n",
    "# behaviour_dataframe = pd.DataFrame(behav_array)\n",
    "# behaviour_dataframe.to_csv(behaviour_Save_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Cells**\n",
    "====================\n",
    "These cells allow for the evaluation of the tuning of various functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Polynomial Detrending Parameters** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate ploynomail detrending\n",
    "neuron_test_detrend = 10\n",
    "#polynomial degree of 15-17 gives good results - but tune for new data!\n",
    "polynomial_test_degree  = 12\n",
    "detrend_one = detrend(smooth_intensities[neuron_test_detrend],polynomial_test_degree)\n",
    "plt.figure(1)\n",
    "plt.plot(detrend_one, c='b')\n",
    "plt.plot(smooth_intensities[neuron_test_detrend], c = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluste ICA vs Ratiometric Artefact Removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New ICA vs Ratiometric\n",
    "\n",
    "a, b = np.asanyarray(norm_Data(intensities[12])), np.asanyarray(norm_Data(intensities_red[12]))\n",
    "plt.plot(a, c = 'g')\n",
    "plt.title('Raw Intensities of GCaMP7 (Green) Channel')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Normalised Intensity')\n",
    "plt.show()\n",
    "plt.plot(b, c = 'r')\n",
    "plt.title('Raw Intensities of tdTomato (Red) Channel')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Normalised Intensity')\n",
    "plt.show()\n",
    "\n",
    "c = (a+1)/(b+1)\n",
    "plt.plot(c)\n",
    "plt.title('Ratiometric Correction of Motion Artefacts')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Intensity Ratio')\n",
    "plt.show()\n",
    "\n",
    "print(min(a))\n",
    "print(min(b))\n",
    "\n",
    "ica_g = ICAdecorr([a],[b],0.05, 10)\n",
    "plt.plot(ica_g[0])\n",
    "plt.title('ICA Correction of Motion Artefacts')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Normalised Intensity')\n",
    "# plt.show()\n",
    "# plot_all(p)\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate FOOPSI Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning for FOOPSI \n",
    "\n",
    "tuning_thresh_foopsi = 0.03\n",
    "\n",
    "evaluation_neuron_foopsi = 0\n",
    "spikes_signal_tuning = FOOPSI_all(normalize(detrended))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(detrended[evaluation_neuron_foopsi])\n",
    "plt.title('detrended signal for Specified Neuron')\n",
    "plt.ylabel('Calcium Signal Detrended Intensity')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(spikes_signal_dR[evaluation_neuron_foopsi])\n",
    "plt.title('FOOPSI Results for Specified Neuron')\n",
    "plt.ylabel('Estimated Neural Activity')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate use of ICA or DeltaR/R to separate signal from noise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ICA artifact removal comparison cell\n",
    "ICA_test_neuron = 9\n",
    "R = intensities_red\n",
    "G = intensities\n",
    "\n",
    "a = decorrelateNeuronsICA(R, G, 0.2)\n",
    "\n",
    "plt.plot(G[ICA_test_neuron], c = 'g')\n",
    "plt.plot(R[ICA_test_neuron], c = 'r')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(a[ICA_test_neuron], c = 'g')\n",
    "plt.title('ICA')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(deltaR[ICA_test_neuron], c = 'r')\n",
    "plt.title('DR/R')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find Raster Plot from Non-DR/R data**    \n",
    "Recalculates the spikes from the raw data and plots the results      \n",
    "Evaluates best input to use with FOOPSI Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raster with non-dR/R - Compare Rasters from different input data\n",
    "\n",
    "Raw_filt, _ = np.asanyarray(filt_nematocytes(intensities, 5, positions))\n",
    "\n",
    "raw_smooth = smoother(Raw_filt, 5)\n",
    "\n",
    "df_f_signal = np.asanyarray(df_f(raw_smooth))\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "for i in range(len(raw_smooth)):\n",
    "    plt.plot(raw_smooth[i])\n",
    "plt.title('Intensity Plot Raw smooth')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Intensity')\n",
    "plt.show()\n",
    "\n",
    "#Create Raster Plot using CAIMAN's FOOPSI function\n",
    "#foopsi (used on non-df/f data)\n",
    "spikes_signal = np.zeros((len(Raw_filt),len(Raw_filt[1])))\n",
    "for i in range(len(Raw_filt)):\n",
    "    ca_foopsi,cb,b1,g,c1,spikes_foopsi,lam = deconv.constrained_foopsi(Raw_filt[i],p=2)\n",
    "    spikes_signal[i] = spikes_foopsi\n",
    "    \n",
    "#foopsi (used on df/f data)\n",
    "spikes_signal_df = np.zeros((len(df_f_signal),len(df_f_signal[1])))\n",
    "for i in range(len(df_f_signal)):\n",
    "    ca_foopsi,cb,b1,g,c1,spikes_foopsi,lam = deconv.constrained_foopsi(df_f_signal[i],p=2)\n",
    "    spikes_signal_df[i] = spikes_foopsi\n",
    "\n",
    "#threshold to find spikes\n",
    "spike_thresh = 0.3\n",
    "\n",
    "raster_array = np.zeros((len(Raw_filt),len(Raw_filt[1])))\n",
    "for i in range(len(spikes_signal)):\n",
    "    for j in range(len(spikes_signal[i])):\n",
    "        if spikes_signal[i][j] >= spike_thresh*max(spikes_signal[i]):\n",
    "            raster_array[i][j] = j\n",
    "\n",
    "raster_array_df = np.zeros((len(df_f_signal),len(df_f_signal[1])))\n",
    "for i in range(len(spikes_signal_df)):\n",
    "    for j in range(len(spikes_signal_df[i])):\n",
    "        if spikes_signal_df[i][j] >= spike_thresh*max(spikes_signal_df[i]):\n",
    "            raster_array_df[i][j] = j\n",
    "\n",
    "#Plot raster for base data\n",
    "#zero values from way array was made array give large syncronous train at start of the signal - should fix (.append method?)\n",
    "plt.figure(3)\n",
    "plt.eventplot(raster_array,linelengths = 0.5)\n",
    "plt.title('Raster Plot of All Neurons (raw intensities)')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.ylabel('Neuron')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(4)\n",
    "plt.eventplot(raster_array_df,linelengths = 0.5)\n",
    "plt.title('Raster Plot of All Neurons (df/f intensities)')\n",
    "plt.xlabel('Frame Number')\n",
    "plt.ylabel('Neuron')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative Clustering Visualisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering Data - evaluate clustering with a cluster map (provides some extra visualisation if you want it but I prefer other methods)\n",
    "#Input Number of Clusters Based on Results from Dendogram\n",
    "\n",
    "eucdist = cdist(CaSignal_norm,CaSignal_norm)\n",
    "cluster = AgglomerativeClustering(n_clusters=number_of_clusters, affinity='euclidean')\n",
    "cluster.fit_predict(CaSignal_norm)\n",
    "plt.figure(figsize=(10, 7))  \n",
    "plt.scatter(eucdist[:,1], eucdist[:,0],c=cluster.labels_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Raster Reshaping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Evaluate Raster Reshaping step for saving as csv\n",
    "\n",
    "# raster_reshape_test_neuron = 5\n",
    "\n",
    "# plt.plot(raster_array_pred[raster_reshape_test_neuron], color = 'r')\n",
    "# plt.eventplot(raster_array_dR[raster_reshape_test_neuron])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Neuron Tracking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 22\n",
    "_,_,_,display = SingleCellIntensity(neuron = n, video = vid, positions = posit_corrected, dimentionROI = dim, Circle_radius = 4, distance_threshold = 4, display_on = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Tracked Neurons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(display)):\n",
    "#     plt.imshow(display[i])\n",
    "#     title = 'neuron_' + str(i) + '.tif'\n",
    "#     plt.savefig(str(title), format = 'tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental Cells\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raster using peak detection function - needs tuning...\n",
    "\n",
    "neuron_for_peaks = 50\n",
    "distance_between_peaks = 10\n",
    "prominance_of_peaks = 0.05\n",
    "\n",
    "a,b = sp.signal.find_peaks(detrended[neuron_for_peaks], distance = distance_between_peaks, prominence = prominance_of_peaks)\n",
    "plt.figure(1)\n",
    "plt.plot(detrended[neuron_for_peaks])\n",
    "plt.plot(a, detrended[neuron_for_peaks][a], 'x')\n",
    "plt.show()\n",
    "\n",
    "raster2 = np.zeros((len(detrended), len(detrended[1])))\n",
    "for i in range(len(detrended)):\n",
    "    peaks,_ = sp.signal.find_peaks(detrended[i], distance = distance_between_peaks, prominence = prominance_of_peaks)\n",
    "    for j in range(len(detrended[i])):\n",
    "        for k in range(len(peaks)):\n",
    "            raster2[i][peaks[k]] = 1\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(raster2[neuron_for_peaks])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency filtering\n",
    "#sampling rate = 3Hz\n",
    "#hmm doesnt seem to work well at all\n",
    "\n",
    "neurons = 10\n",
    "\n",
    "frqs = np.fft.fft(detrended[neuron])\n",
    "xax = np.arange(0,6000, 6000/(len(detrended[0])))\n",
    "plt.figure(1)\n",
    "plt.title('Fourier Spectrum')\n",
    "plt.plot(abs(frqs.real))\n",
    "\n",
    "\n",
    "#freqs adjusted\n",
    "filter_block = np.ones(len(detrended[0]))\n",
    "low_pass_cut = 30\n",
    "filter_block[low_pass_cut:len(filter_block)-low_pass_cut] = 0\n",
    "#filter_block[len(filter_block) - 80: len(filter_block) - 55] = 1\n",
    "plt.plot(filter_block)\n",
    "plt.show()\n",
    "new_freqs = np.fft.ifft(frqs*filter_block)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(new_freqs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #independant component analysis to separate noise - single neuron\n",
    "\n",
    "# ica_test_neuron = 9\n",
    "# window = 5\n",
    "\n",
    "# data_green = [intensities[ica_test_neuron]]\n",
    "# filtered_data_g = smoother(data_green,window)\n",
    "# filtered_data_g = np.transpose(detrend(np.transpose(filtered_data_g), 17))\n",
    "# plt.figure(1)\n",
    "# plt.plot(filtered_data_g[0],c='g')\n",
    "# # plt.plot(data_green[0],'r')\n",
    "\n",
    "# data_red = [intensities_red[ica_test_neuron]]\n",
    "# filtered_data_r = smoother(data_red,window)\n",
    "# filtered_data_r = np.transpose(detrend(np.transpose(filtered_data_r), 17))\n",
    "# plt.figure(2)\n",
    "# plt.plot(filtered_data_r[0],c='r')\n",
    "# # plt.plot(data_red[0],'r')\n",
    "# plt.show()\n",
    "\n",
    "# X = np.c_[filtered_data_g[0],filtered_data_r[0]]\n",
    "# print(X.shape)\n",
    "# X = X.reshape(len(filtered_data_g[0]),2)\n",
    "# print(X.shape)\n",
    "# # scaler= StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "# # X = scaler.fit_transform(X)\n",
    "# ica = FastICA(n_components = 2, random_state = None)\n",
    "# A = ica.fit_transform(X)\n",
    "\n",
    "# plt.figure(3)\n",
    "# plt.plot(X[:,0], c='g')\n",
    "# plt.plot(X[:,1], c='r')\n",
    "# plt.plot(data_green, c='b')\n",
    "# plt.plot(data_red, c='y')\n",
    "# plt.figure(4)\n",
    "# plt.plot(A[:,0])\n",
    "# plt.plot(A[:,1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Correlation Between Neural Activity and Behaviour\n",
    "# #Method finds change in neural activity between CB and RP\n",
    "\n",
    "# #select neuron to observe\n",
    "# neuron = 44\n",
    "\n",
    "# #select lenght of sub sequences (will depend on number of frames behaviour takes up)\n",
    "# seqlen = 100\n",
    "\n",
    "# df_on = smooth_intensities[neuron][301:565] + smooth_intensities[neuron][991:1076]\n",
    "# df_ons = []\n",
    "# for i in range(int(len(df_on)/seqlen)):\n",
    "#     df_ons.append(df_on[i*seqlen:(i*seqlen)+seqlen])\n",
    "\n",
    "# df_off = smooth_intensities[neuron][0:301] + smooth_intensities[neuron][565:991] + smooth_intensities[neuron][1076: len(smooth_intensities[0])]\n",
    "# df_offs = []\n",
    "# for i in range(int(len(df_off)/seqlen)):\n",
    "#     df_offs.append(df_off[i*seqlen:(i*seqlen)+seqlen])\n",
    "    \n",
    "# #find average of on signal\n",
    "# avg_on = []\n",
    "# for i in range(len(df_ons[0])):\n",
    "#     values = []\n",
    "#     for j in range(len(df_ons)):\n",
    "#         values.append(df_ons[j][i]) \n",
    "#     avg_on.append(np.mean(values))\n",
    "\n",
    "# #find average of off signal\n",
    "# avg_off = []\n",
    "# for i in range(len(df_offs[0])):\n",
    "#     values = []\n",
    "#     for j in range(len(df_offs)):\n",
    "#         values.append(df_offs[j][i]) \n",
    "#     avg_off.append(np.mean(values))\n",
    "\n",
    "# #correlation\n",
    "# corr_on_off = np.corrcoef(avg_off,avg_on)[0,1]\n",
    "# print('Pearson Correlation Coeff: ', corr_on_off)\n",
    "\n",
    "# #if correlation is very low, neurons change activity patterns during behaviour!!\n",
    "# if abs(corr_on_off) < 0.5:\n",
    "#     print('Neuron Changes Activity During Behaviour')\n",
    "# else:\n",
    "#     print('Neuron Does Not Change Activity During Behaviour')\n",
    "    \n",
    "# plt.plot(avg_on)\n",
    "# plt.plot(avg_off)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
